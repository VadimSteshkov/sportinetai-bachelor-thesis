{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec03dfd-7e6d-4d86-a5bb-e2c91b2047c6",
   "metadata": {},
   "source": [
    "# Statistical DataFrame for Fight Outcome Prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a262a-493d-45cb-80b9-6303bc569bfa",
   "metadata": {},
   "source": [
    "#### This DataFrame is structured to support predictive modeling of UFC fight outcomes, consolidating key fight statistics, event details, and fighter attributes. It includes essential metrics such as fight method, fighter stance, age, reach, and historical performance records, all of which contribute to the analysis and prediction of fight results. This dataset serves as a comprehensive foundation for building machine learning models that forecast the outcome of MMA fights based on fighters' skills, physical attributes, and fight histories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497972a-22c4-4081-9a21-b8e46320335f",
   "metadata": {},
   "source": [
    "\n",
    "1. **event_name**: The name of the UFC event.\n",
    "2. **date**: The date of the event.\n",
    "3. **location**: The venue and city where the event occurred.\n",
    "4. **fighter (red/blue)**: Names of the fighters in the red and blue corners.\n",
    "5. **winner**: Indicates the winner of the fight (either \"Red\" or \"Blue\").\n",
    "6. **weight_class**: The weight division for the fight (e.g., Featherweight, Welterweight).\n",
    "7. **is_title_bout**: Indicates if the fight was for a championship title (1 for yes, 0 for no).\n",
    "8. **gender**: Gender category of the fighters (\"Men\" or \"Women\").\n",
    "9. **method**: How the fight was won (e.g., \"Decision\", \"KO/TKO\", \"Submission\").\n",
    "10. **round**: The round in which the fight ended.\n",
    "11. **time**: The time in the specified round when the fight ended.\n",
    "12. **time_format**: Format of the time, such as \"3 Rnd (5-5-5)\".\n",
    "13. **referee**: The official who oversaw the fight.\n",
    "\n",
    "### Fight Statistics (for both red and blue fighters)\n",
    "- **kd**: Number of knockdowns.\n",
    "- **sig_str**: Significant strikes landed.\n",
    "- **sig_str_att**: Significant strikes attempted.\n",
    "- **total_str**: Total strikes landed.\n",
    "- **total_str_att**: Total strikes attempted.\n",
    "- **td**: Takedowns landed.\n",
    "- **td_att**: Takedowns attempted.\n",
    "- **sub_att**: Submission attempts.\n",
    "- **pass**: Number of guard passes.\n",
    "- **rev**: Number of reversals.\n",
    "\n",
    "### Differences Between Fighters\n",
    "- **age_diff**: Age difference.\n",
    "- **height_diff**: Height difference.\n",
    "- **reach_diff**: Reach difference.\n",
    "- **weight_diff**: Weight difference.\n",
    "\n",
    "### Striking Metrics\n",
    "- **SLpM_total_diff**: Difference in significant strikes landed per minute.\n",
    "- **SApM_total_diff**: Difference in significant strikes absorbed per minute.\n",
    "- **sig_str_acc_total_diff**: Difference in significant strike accuracy.\n",
    "- **str_def_total_diff**: Difference in striking defense.\n",
    "\n",
    "### Takedown Metrics\n",
    "- **td_avg_diff**: Difference in average takedowns per 15 minutes.\n",
    "- **td_acc_total_diff**: Difference in takedown accuracy.\n",
    "- **td_def_total_diff**: Difference in takedown defense.\n",
    "\n",
    "### Submission Metrics\n",
    "- **sub_avg_diff**: Difference in average submission attempts.\n",
    "\n",
    "### Fighter Records and Trends\n",
    "- **current_win_streak**: Current win streak.\n",
    "- **current_lose_streak**: Current losing streak.\n",
    "- **draw**: Number of draws.\n",
    "- **longest_win_streak**: Longest win streak.\n",
    "- **total_fights**: Total number of fights.\n",
    "- **total_rounds_fought**: Total rounds fought.\n",
    "- **total_title_bouts**: Total title bouts.\n",
    "- **record**: Win-loss-draw record.\n",
    "- **win_by_KO_TKO**: Wins by KO/TKO.\n",
    "- **win_by_Submission**: Wins by submission.\n",
    "- **win_by_Decision**: Wins by decision.\n",
    "\n",
    "### Fight End and Performance\n",
    "- **finish**: Indicates if the fight ended in a finish (KO/TKO or Submission).\n",
    "- **fight_end**: How the fight ended (e.g., \"Decision\", \"KO\").\n",
    "- **avg_performance**: Average performance rating.\n",
    "- **rating_trend**: Trend in performance rating.\n",
    "\n",
    "### Win Probability\n",
    "- **prob_win**: Probability of winning for each fighter.\n",
    "\n",
    "### Miscellaneous Differences\n",
    "- **average_fight_time_diff**: Difference in average fight time.\n",
    "- **finish_rate_diff**: Difference in finish rates.\n",
    "\n",
    "### Recent Performance Metrics\n",
    "- **last_5_win_rate**: Win rate in the last 5 fights.\n",
    "- **last_5_finish_rate**: Finish rate in the last 5 fights.\n",
    "\n",
    "### Conditioning\n",
    "- **avg_weight_diff_opponent**: Average weight difference with opponents.\n",
    "\n",
    "### Trends and Experience\n",
    "- **performance_trend_long**: Long-term performance trend.\n",
    "- **knockdown_rate**: Knockdown rate.\n",
    "- **last_title_bout_performance**: Performance in the most recent title bout.\n",
    "- **total_win_rate_diff**: Difference in win rates.\n",
    "- **total_finish_rate_diff**: Difference in finish rates.\n",
    "- **experience_diff**: Difference in overall experience.\n",
    "- **experience_trend**: Experience trend.\n",
    "- **career_span_diff**: Difference in career duration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "0749d639-e212-4194-88f8-452fdff159e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:58.937035Z",
     "start_time": "2024-12-22T17:50:58.930898Z"
    }
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "91347f01-4d7d-450a-ab8b-7768ae593145",
   "metadata": {},
   "source": [
    "## Comprehensive Data Quality Checks for UFC Fight Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb833f72-6b30-4664-ba6d-45aba782807a",
   "metadata": {},
   "source": [
    "#### This script performs essential data quality checks on UFC-related datasets to ensure readiness for predictive modeling. It loads multiple datasets, examines them for missing values, duplicates, and data type consistency, and provides statistical summaries. The insights generated help validate and prepare the data for further analysis and model training"
   ]
  },
  {
   "cell_type": "code",
   "id": "92ce7ba7-ab48-494c-97fb-33339d361407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:59.045997Z",
     "start_time": "2024-12-22T17:50:58.977654Z"
    }
   },
   "source": [
    "\n",
    "# Function for data quality checks\n",
    "def data_quality_checks(df, df_name):\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    \n",
    "    # Check data types\n",
    "    data_types = df.dtypes\n",
    "    \n",
    "    # Count of unique values for certain columns\n",
    "    unique_values = df.nunique()\n",
    "    \n",
    "    # Statistical summary for numerical columns\n",
    "    stats_summary = df.describe()\n",
    "\n",
    "    # Get the list of all column names\n",
    "    column_names = df.columns.tolist()\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"\\nColumn Names:\")\n",
    "    print(column_names)\n",
    "    print(f\"\\n=== Data Quality Checks for {df_name} ===\")\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "    print(f\"\\nNumber of Duplicate Rows: {duplicate_rows}\")\n",
    "    print(\"\\nData Types:\")\n",
    "    print(data_types)\n",
    "    print(\"\\nUnique Values Count:\")\n",
    "    print(unique_values)\n",
    "    print(\"\\nStatistical Summary for Numerical Columns:\")\n",
    "    print(stats_summary)\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "fighter_stats = pd.read_csv('data/raw/Fighter_stats/fighter_stats.csv')\n",
    "large_dataset = pd.read_csv('data/raw/Large_set/large_dataset.csv')\n",
    "medium_dataset = pd.read_csv('data/raw/Medium_set/medium_dataset.csv')\n",
    "ufc = pd.read_csv('data/raw/ufc.csv')\n",
    "ufc_master = pd.read_csv('data/raw/ufc-master.csv')\n",
    "completed_events_small = pd.read_csv('data/raw/Small_set/completed_events_small.csv')\n",
    "\n",
    "# Perform data quality checks for each dataset\n",
    "data_quality_checks(fighter_stats, \"Fighter Stats\")\n",
    "data_quality_checks(large_dataset, \"Large Dataset\")\n",
    "data_quality_checks(medium_dataset, \"Medium Dataset\")\n",
    "data_quality_checks(ufc, \"UFC\")\n",
    "data_quality_checks(ufc_master, \"UFC Master\")\n",
    "data_quality_checks(completed_events_small, \"Completed Events Small\")\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/Large_set/large_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Load the datasets\u001B[39;00m\n\u001B[1;32m     37\u001B[0m fighter_stats \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/raw/Fighter_stats/fighter_stats.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 38\u001B[0m large_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/raw/Large_set/large_dataset.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m medium_dataset \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/raw/Medium_set/medium_dataset.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     40\u001B[0m ufc \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/raw/ufc.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/raw/Large_set/large_dataset.csv'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "2ff62a0f-dc17-4e7f-a334-773e66653edd",
   "metadata": {},
   "source": [
    "## Merging and Organizing UFC Event Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cbd3f-5336-4613-89f5-2686717e87d6",
   "metadata": {},
   "source": [
    "This script loads and merges two UFC-related datasets based on a common column, `event_name`, to create a unified DataFrame. After merging, it reorders columns to place the `date` and `location` fields immediately after `event_name` for logical organization. Finally, it displays the first few rows of the merged DataFrame to confirm the updates, providing a streamlined dataset for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfd4af24-f0d5-4c65-8b7b-290767b27f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             event_name       date                location  \\\n",
      "0  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "1  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "2  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "3  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "4  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "\n",
      "      r_fighter       b_fighter winner       weight_class  is_title_bout  \\\n",
      "0  Amanda Ribas  Rose Namajunas   Blue  Women's Flyweight              0   \n",
      "1  Amanda Ribas  Rose Namajunas   Blue  Women's Flyweight              0   \n",
      "2  Amanda Ribas  Rose Namajunas   Blue  Women's Flyweight              0   \n",
      "3  Amanda Ribas  Rose Namajunas   Blue  Women's Flyweight              0   \n",
      "4  Amanda Ribas  Rose Namajunas   Blue  Women's Flyweight              0   \n",
      "\n",
      "  gender                method  ...  weight_diff  reach_diff  SLpM_total_diff  \\\n",
      "0  Women  Decision - Unanimous  ...          0.0        2.54             0.94   \n",
      "1  Women  Decision - Unanimous  ...          0.0        2.54             0.94   \n",
      "2  Women  Decision - Unanimous  ...          0.0        2.54             0.94   \n",
      "3  Women  Decision - Unanimous  ...          0.0        2.54             0.94   \n",
      "4  Women  Decision - Unanimous  ...          0.0        2.54             0.94   \n",
      "\n",
      "  SApM_total_diff  sig_str_acc_total_diff  td_acc_total_diff  \\\n",
      "0           -0.11                   -0.01               0.04   \n",
      "1           -0.11                   -0.01               0.04   \n",
      "2           -0.11                   -0.01               0.04   \n",
      "3           -0.11                   -0.01               0.04   \n",
      "4           -0.11                   -0.01               0.04   \n",
      "\n",
      "   str_def_total_diff  td_def_total_diff  sub_avg_diff  td_avg_diff  \n",
      "0               -0.02               0.26           0.2         0.69  \n",
      "1               -0.02               0.26           0.2         0.69  \n",
      "2               -0.02               0.26           0.2         0.69  \n",
      "3               -0.02               0.26           0.2         0.69  \n",
      "4               -0.02               0.26           0.2         0.69  \n",
      "\n",
      "[5 rows x 97 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xk/3tkdytbd6592ydbb9rrbqkpc0000gn/T/ipykernel_3833/2077510748.py:26: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  merged_dataset = merged_dataset.loc[:, pd.unique(new_columns_order)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the datasets\n",
    "large_dataset = pd.read_csv('data/raw/Large_set/large_dataset.csv')\n",
    "medium_dataset = pd.read_csv('data/raw/Medium_set/medium_dataset.csv')\n",
    "\n",
    "# Rename columns for matching\n",
    "medium_dataset = medium_dataset.rename(columns={'event': 'event_name'})\n",
    "\n",
    "# Merge the datasets on the common column (event_name), без method_details\n",
    "merged_dataset = pd.merge(large_dataset, medium_dataset[['event_name', 'date', 'location']],\n",
    "                          on='event_name', how='left')\n",
    "\n",
    "# Reorder columns: place 'date' after 'event_name' and 'location' after 'date'\n",
    "columns_order = merged_dataset.columns.tolist()\n",
    "event_name_idx = columns_order.index('event_name')\n",
    "\n",
    "# Rearrange the column order\n",
    "new_columns_order = (\n",
    "    columns_order[:event_name_idx + 1] +  # Up to and including 'event_name'\n",
    "    ['date', 'location'] +                # Add 'date' and 'location' after 'event_name'\n",
    "    columns_order[event_name_idx + 1:]    # Remaining columns\n",
    ")\n",
    "\n",
    "# Apply the new column order\n",
    "merged_dataset = merged_dataset.loc[:, pd.unique(new_columns_order)]\n",
    "\n",
    "# Display the updated DataFrame to confirm the changes\n",
    "print(merged_dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d79a1-636d-48ca-bc22-7987823aa32a",
   "metadata": {},
   "source": [
    "## Analysis of Missing and Duplicate Data in UFC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3a786-4e29-4dbb-ad9b-0cf1e76a1e15",
   "metadata": {},
   "source": [
    "This code identifies and analyzes missing and duplicate data within the merged UFC dataset. It calculates both the count and percentage of missing values for each column, creating a summary `DataFrame` that highlights only columns with missing data. It also counts the total number of duplicate rows in the dataset. The results provide insights into data completeness and help identify areas requiring data cleaning or imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61ca4aff-1568-4ec9-bfa6-46cf560338ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Missing Values:\n",
      "              Missing Values Count  Missing Values Percentage\n",
      "date                            12                   0.014380\n",
      "location                        12                   0.014380\n",
      "total_rounds                   361                   0.432610\n",
      "referee                        384                   0.460172\n",
      "r_age                          718                   0.860426\n",
      "r_reach                       3880                   4.649658\n",
      "r_stance                       275                   0.329550\n",
      "b_age                         1762                   2.111520\n",
      "b_reach                       8507                  10.194495\n",
      "b_stance                       713                   0.854435\n",
      "age_diff                      1962                   2.351193\n",
      "reach_diff                   10069                  12.066342\n",
      "\n",
      "Number of Duplicate Rows: 76008\n"
     ]
    }
   ],
   "source": [
    "# Analysis of missing values\n",
    "missing_values_count = merged_dataset.isnull().sum()\n",
    "missing_values_percentage = (missing_values_count / len(merged_dataset)) * 100\n",
    "\n",
    "# Combine the count and percentage of missing values into one DataFrame\n",
    "missing_data_analysis = pd.DataFrame({\n",
    "    'Missing Values Count': missing_values_count,\n",
    "    'Missing Values Percentage': missing_values_percentage\n",
    "})\n",
    "\n",
    "# Filter only those columns with missing values\n",
    "missing_data_analysis = missing_data_analysis[missing_data_analysis['Missing Values Count'] > 0]\n",
    "\n",
    "# Analysis of duplicate rows\n",
    "duplicate_rows_count = merged_dataset.duplicated().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"Analysis of Missing Values:\")\n",
    "print(missing_data_analysis)\n",
    "\n",
    "print(\"\\nNumber of Duplicate Rows:\", duplicate_rows_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8df1eb-355b-476d-8270-6b8ff32a1c14",
   "metadata": {},
   "source": [
    "## Removing Duplicate Rows from Merged UFC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39c8bd-d228-481c-9231-603b1fb16702",
   "metadata": {},
   "source": [
    "This code removes duplicate rows from the merged UFC dataset to ensure data integrity. After dropping duplicates, it rechecks for any remaining duplicate rows and outputs the count to confirm their successful removal. The updated `DataFrame` is displayed to verify the changes, ensuring a clean dataset for analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20e384f5-1dde-489e-ac1b-8b63a09a7f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows After Removal: 0\n",
      "                              event_name       date                location  \\\n",
      "0   UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "13  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "26  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "39  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "52  UFC Fight Night: Ribas vs. Namajunas  3/23/2024  Las Vegas, Nevada, USA   \n",
      "\n",
      "            r_fighter        b_fighter winner       weight_class  \\\n",
      "0        Amanda Ribas   Rose Namajunas   Blue  Women's Flyweight   \n",
      "13      Karl Williams      Justin Tafa    Red        Heavyweight   \n",
      "26   Edmen Shahbazyan        AJ Dobson    Red       Middleweight   \n",
      "39     Payton Talbott  Cameron Saaiman    Red       Bantamweight   \n",
      "52  Billy Quarantillo    Youssef Zalal   Blue      Featherweight   \n",
      "\n",
      "    is_title_bout gender                method  ...  weight_diff  reach_diff  \\\n",
      "0               0  Women  Decision - Unanimous  ...         0.00        2.54   \n",
      "13              0    Men  Decision - Unanimous  ...       -13.16       12.70   \n",
      "26              0    Men                KO/TKO  ...         0.00       -2.54   \n",
      "39              0    Men                KO/TKO  ...         0.00        7.62   \n",
      "52              0    Men            Submission  ...         0.00       -5.08   \n",
      "\n",
      "    SLpM_total_diff SApM_total_diff  sig_str_acc_total_diff  \\\n",
      "0              0.94           -0.11                   -0.01   \n",
      "13            -1.22           -3.32                   -0.02   \n",
      "26            -0.69           -1.22                    0.06   \n",
      "39             2.73           -0.60                    0.08   \n",
      "52             4.48            3.84                    0.07   \n",
      "\n",
      "    td_acc_total_diff  str_def_total_diff  td_def_total_diff  sub_avg_diff  \\\n",
      "0                0.04               -0.02               0.26           0.2   \n",
      "13               0.50                0.13               0.50           0.2   \n",
      "26              -0.37               -0.01              -0.02           0.3   \n",
      "39              -0.28                0.00               0.43          -0.2   \n",
      "52              -0.11               -0.22               0.01          -0.2   \n",
      "\n",
      "    td_avg_diff  \n",
      "0          0.69  \n",
      "13         4.75  \n",
      "26         0.57  \n",
      "39        -0.91  \n",
      "52        -1.04  \n",
      "\n",
      "[5 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "merged_dataset = merged_dataset.drop_duplicates()\n",
    "\n",
    "# Check again for duplicate rows\n",
    "duplicate_rows_count_after = merged_dataset.duplicated().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"Number of Duplicate Rows After Removal:\", duplicate_rows_count_after)\n",
    "\n",
    "# Display the updated DataFrame to confirm the changes\n",
    "print(merged_dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082808f-e9a7-4155-bcc1-9ebaeaf35dee",
   "metadata": {},
   "source": [
    "## Assessing Missing and Duplicate Data in UFC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "314aa913-3253-404b-b1d8-bdef8f700cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Missing Values:\n",
      "              Missing Values Count  Missing Values Percentage\n",
      "date                            12                   0.161312\n",
      "location                        12                   0.161312\n",
      "total_rounds                    31                   0.416723\n",
      "referee                         32                   0.430165\n",
      "r_age                           76                   1.021643\n",
      "r_reach                        412                   5.538379\n",
      "r_stance                        26                   0.349509\n",
      "b_age                          190                   2.554107\n",
      "b_reach                        888                  11.937088\n",
      "b_stance                        68                   0.914101\n",
      "age_diff                       213                   2.863288\n",
      "reach_diff                    1038                  13.953488\n",
      "\n",
      "Number of Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Analysis of missing values\n",
    "missing_values_count = merged_dataset.isnull().sum()\n",
    "missing_values_percentage = (missing_values_count / len(merged_dataset)) * 100\n",
    "\n",
    "# Combine the count and percentage of missing values into one DataFrame\n",
    "missing_data_analysis = pd.DataFrame({\n",
    "    'Missing Values Count': missing_values_count,\n",
    "    'Missing Values Percentage': missing_values_percentage\n",
    "})\n",
    "\n",
    "# Filter only those columns with missing values\n",
    "missing_data_analysis = missing_data_analysis[missing_data_analysis['Missing Values Count'] > 0]\n",
    "\n",
    "# Analysis of duplicate rows\n",
    "duplicate_rows_count = merged_dataset.duplicated().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"Analysis of Missing Values:\")\n",
    "print(missing_data_analysis)\n",
    "\n",
    "print(\"\\nNumber of Duplicate Rows:\", duplicate_rows_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6153a1-3049-42ea-952b-d1abc59228b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a580f-fbbd-4996-895e-edc2bc9bf56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf4241d6-5768-4baa-997d-19ee2045d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the current DataFrame to the specified path with a descriptive filename\n",
    "merged_dataset.to_csv('data/processed/ufc_fight_data_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe3793-1311-402a-a1d4-8c468399d7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SportiNetAI)",
   "language": "python",
   "name": "sportinetai_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
