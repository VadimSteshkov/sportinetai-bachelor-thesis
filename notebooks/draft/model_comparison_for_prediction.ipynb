{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3cab46-4fa6-4afa-929a-6509f791458b",
   "metadata": {},
   "source": [
    "# Build a Prediction Model Using the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50cdad-7ae0-4c3a-a0d5-593751cb2c3b",
   "metadata": {},
   "source": [
    "### In this file, I will train and test several models for predicting fight outcomes to select the best one that provides the highest accuracy and meets all necessary functional requirements. Comparing the models will help identify which one is most suitable for our task and demonstrates the best performance in the context of fight outcome prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff10c02-4c4a-4509-a88f-3e51a553775e",
   "metadata": {},
   "source": [
    "## Data Loading and Missing Values Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd59807f-a443-4436-b75a-cadffb1e7254",
   "metadata": {},
   "source": [
    "This code loads the cleaned UFC dataset and performs an analysis to identify any missing values. It calculates the count and percentage of missing values for each column, displaying a table with columns that contain missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "784830ac-0359-4e7a-a99d-91dfa0096590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b6572f-9a7a-4e30-b8c5-aa8f41e8d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values and their percentage:\n",
      "              Missing Values  Percentage\n",
      "date                      12    0.161312\n",
      "location                  12    0.161312\n",
      "total_rounds              31    0.416723\n",
      "referee                   32    0.430165\n",
      "r_age                     76    1.021643\n",
      "r_reach                  412    5.538379\n",
      "r_stance                  26    0.349509\n",
      "b_age                    190    2.554107\n",
      "b_reach                  888   11.937088\n",
      "b_stance                  68    0.914101\n",
      "age_diff                 213    2.863288\n",
      "reach_diff              1038   13.953488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load data\n",
    "ufc_data = pd.read_csv('../data/processed/ufc_fight_data_cleaned.csv')\n",
    "\n",
    "# Step 2: Check for missing values\n",
    "missing_values = ufc_data.isnull().sum()\n",
    "missing_percentage = (missing_values / len(ufc_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "missing_data = missing_data[missing_data['Missing Values'] > 0]  # Only columns with missing values\n",
    "\n",
    "print(\"Columns with missing values and their percentage:\")\n",
    "print(missing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654b9ef-2650-45c0-a54a-8c81ac7d5537",
   "metadata": {},
   "source": [
    "## Handling Missing Values in Numeric and Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520d9d3-4306-4faa-b587-c14800ac4ae4",
   "metadata": {},
   "source": [
    "his code fills missing values in the dataset. Numeric columns are filled with the mean of each column, while categorical columns are filled with the mode (most frequent value) of each column. A final check is then performed to ensure there are no remaining missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6fd7106-1485-4443-89de-55098efd6e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric columns filled with mean:\n",
      "              Missing Values  Percentage\n",
      "total_rounds              31    0.416723\n",
      "r_age                     76    1.021643\n",
      "r_reach                  412    5.538379\n",
      "b_age                    190    2.554107\n",
      "b_reach                  888   11.937088\n",
      "age_diff                 213    2.863288\n",
      "reach_diff              1038   13.953488\n",
      "\n",
      "Categorical columns filled with mode:\n",
      "          Missing Values  Percentage\n",
      "date                  12    0.161312\n",
      "location              12    0.161312\n",
      "referee               32    0.430165\n",
      "r_stance              26    0.349509\n",
      "b_stance              68    0.914101\n",
      "\n",
      "Remaining missing values after filling:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Separate and fill missing values\n",
    "\n",
    "# Fill numeric columns with mean\n",
    "numeric_columns = ufc_data.select_dtypes(include=['number']).columns\n",
    "numeric_missing = missing_data.loc[numeric_columns.intersection(missing_data.index)]\n",
    "ufc_data[numeric_columns] = ufc_data[numeric_columns].fillna(ufc_data[numeric_columns].mean())\n",
    "\n",
    "print(\"\\nNumeric columns filled with mean:\")\n",
    "print(numeric_missing)\n",
    "\n",
    "# Fill categorical columns with mode\n",
    "categorical_columns = ufc_data.select_dtypes(include=['object']).columns\n",
    "categorical_missing = missing_data.loc[categorical_columns.intersection(missing_data.index)]\n",
    "for column in categorical_columns:\n",
    "    ufc_data[column].fillna(ufc_data[column].mode()[0], inplace=True)\n",
    "\n",
    "print(\"\\nCategorical columns filled with mode:\")\n",
    "print(categorical_missing)\n",
    "\n",
    "# Final check for any remaining missing values\n",
    "print(\"\\nRemaining missing values after filling:\")\n",
    "print(ufc_data.isnull().sum().sum())  # Total count of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554bd56-8fb0-44e5-ab7f-7fa9ece826e0",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables and Defining Features and Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4836047f-9597-4659-9e71-7290b5dbdd41",
   "metadata": {},
   "source": [
    "This code converts categorical variables to a numeric format using one-hot encoding. It then defines the feature matrix `X`, which includes all columns except `winner_Red`, and the target variable `y`, represented by the `winner_Red` column, indicating the victory of the fighter in the red corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "172a1cd3-cc89-4243-9f50-ca75046165d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "ufc_data_encoded = pd.get_dummies(ufc_data, drop_first=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X = ufc_data_encoded.drop(columns=['winner_Red'])  # Adjust `winner_Red` if needed\n",
    "y = ufc_data_encoded['winner_Red']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f0600-92e8-420b-8fe6-a5c6f8d644ba",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae049f7-2af2-48f3-91b3-1367618474c1",
   "metadata": {},
   "source": [
    "This code splits the dataset into training and testing sets using the `train_test_split` function from scikit-learn. Here, 20% of the data is allocated for testing, while the remaining 80% is used for training the model. The `random_state=42` parameter ensures reproducibility of the data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed07f95f-1e4f-40b1-9114-d2764ac5d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aee4f8-842a-48db-9f21-8f73d71527c6",
   "metadata": {},
   "source": [
    "## Training and Evaluating Models for Fight Outcome Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edce795e-fca4-40f7-a9a0-bcf27e571fc0",
   "metadata": {},
   "source": [
    "This code applies three models — Logistic Regression, Random Forest, and XGBoost — to predict the fight winner. Each model is trained on the training data and evaluated on the test data. Logistic Regression includes data scaling, while Random Forest and XGBoost operate without it. For each model, accuracy is calculated, and a classification report is displayed to analyze the performance metrics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d12c30f7-2406-4f7d-886e-5269a1ed8f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.8158602150537635\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.77      0.74       517\n",
      "        True       0.87      0.84      0.86       971\n",
      "\n",
      "    accuracy                           0.82      1488\n",
      "   macro avg       0.80      0.81      0.80      1488\n",
      "weighted avg       0.82      0.82      0.82      1488\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.8870967741935484\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.79      0.83       517\n",
      "        True       0.89      0.94      0.92       971\n",
      "\n",
      "    accuracy                           0.89      1488\n",
      "   macro avg       0.88      0.86      0.87      1488\n",
      "weighted avg       0.89      0.89      0.89      1488\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.918010752688172\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.86      0.88       517\n",
      "        True       0.93      0.95      0.94       971\n",
      "\n",
      "    accuracy                           0.92      1488\n",
      "   macro avg       0.91      0.90      0.91      1488\n",
      "weighted avg       0.92      0.92      0.92      1488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "# Logistic Regression with scaling\n",
    "log_reg_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=2000, random_state=42)\n",
    ")\n",
    "train_and_evaluate_model(log_reg_model, \"Logistic Regression\")\n",
    "\n",
    "# Random Forest (no need for scaling)\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "train_and_evaluate_model(rf_model, \"Random Forest\")\n",
    "\n",
    "# XGBoost (ensure no warnings by using updated parameters)\n",
    "xgb_model = XGBClassifier(scale_pos_weight=(y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]), eval_metric='logloss')\n",
    "train_and_evaluate_model(xgb_model, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90ce77-c651-4c89-b87c-330f1cf5b654",
   "metadata": {},
   "source": [
    "## Fighter Data Preparation and Outcome Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360243f-f258-404a-b818-fe6314a21779",
   "metadata": {},
   "source": [
    "This code implements functions to prepare data for two fighters and make predictions using trained models. The `prepare_fight_data` function extracts and averages numeric data for each fighter, creating a test dataset with their characteristics. The `predict_for_fighters` function then uses this dataset to predict the outcome of a match between two selected fighters, assigning each to a corner (Red or Blue). Prediction results are displayed for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f7d50dc-2251-42f5-8ac5-524a7e8197d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction results for Islam Makhachev (Red) vs Dustin Poirier (Blue):\n",
      "Logistic Regression Prediction: Blue (Dustin Poirier)\n",
      "Random Forest Prediction: Red (Islam Makhachev)\n",
      "XGBoost Prediction: Red (Islam Makhachev)\n",
      "\n",
      "Prediction results for Dustin Poirier (Red) vs Islam Makhachev (Blue):\n",
      "Logistic Regression Prediction: Red (Dustin Poirier)\n",
      "Random Forest Prediction: Red (Dustin Poirier)\n",
      "XGBoost Prediction: Red (Dustin Poirier)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the main dataset\n",
    "ufc_data = pd.read_csv('../data/processed/ufc_fight_data_cleaned.csv')\n",
    "\n",
    "# Prepare fight data function\n",
    "def prepare_fight_data(df, r_fighter_name, b_fighter_name):\n",
    "    r_fighter_data = df[df['r_fighter'] == r_fighter_name]\n",
    "    b_fighter_data = df[df['b_fighter'] == b_fighter_name]\n",
    "\n",
    "    if not r_fighter_data.empty and not b_fighter_data.empty:\n",
    "        r_fighter_avg = r_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        b_fighter_avg = b_fighter_data.select_dtypes(include=['number']).mean()\n",
    "\n",
    "        test_data = pd.DataFrame()\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col.startswith('r_'):\n",
    "                test_data[col] = [r_fighter_avg.get(col, 0)]\n",
    "            elif col.startswith('b_'):\n",
    "                test_data[col] = [b_fighter_avg.get(col, 0)]\n",
    "\n",
    "        test_data_encoded = pd.get_dummies(test_data, drop_first=True)\n",
    "        test_data_encoded = test_data_encoded.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "        return test_data_encoded\n",
    "    else:\n",
    "        print(\"Data for one or both fighters not available in the dataset.\")\n",
    "        return None\n",
    "\n",
    "# Testing the model predictions\n",
    "def predict_for_fighters(models, r_fighter_name, b_fighter_name):\n",
    "    test_data_encoded = prepare_fight_data(ufc_data, r_fighter_name, b_fighter_name)\n",
    "    \n",
    "    if test_data_encoded is not None:\n",
    "        print(f\"\\nPrediction results for {r_fighter_name} (Red) vs {b_fighter_name} (Blue):\")\n",
    "        for model, model_name in models:\n",
    "            prediction = model.predict(test_data_encoded)\n",
    "            result = f\"Red ({r_fighter_name})\" if prediction[0] else f\"Blue ({b_fighter_name})\"\n",
    "            print(f\"{model_name} Prediction: {result}\")\n",
    "\n",
    "# Define models list\n",
    "models = [\n",
    "    (log_reg_model, \"Logistic Regression\"),\n",
    "    (rf_model, \"Random Forest\"),\n",
    "    (xgb_model, \"XGBoost\")\n",
    "]\n",
    "\n",
    "# Predictions with Islam Makhachev as Red and Dustin Poirier as Blue\n",
    "predict_for_fighters(models, 'Islam Makhachev', 'Dustin Poirier')\n",
    "\n",
    "# Predictions with Dustin Poirier as Red and Islam Makhachev as Blue\n",
    "predict_for_fighters(models, 'Dustin Poirier', 'Islam Makhachev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "662572db-0f21-4ee4-9b36-1793fd671fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['event_name', 'date', 'location', 'winner', 'weight_class',\n",
      "       'is_title_bout', 'gender', 'method', 'finish_round', 'total_rounds',\n",
      "       'time_sec', 'referee', 'kd_diff', 'sig_str_diff', 'sig_str_att_diff',\n",
      "       'sig_str_acc_diff', 'str_diff', 'str_att_diff', 'str_acc_diff',\n",
      "       'td_diff', 'td_att_diff', 'td_acc_diff', 'sub_att_diff', 'rev_diff',\n",
      "       'ctrl_sec_diff', 'wins_total_diff', 'losses_total_diff', 'age_diff',\n",
      "       'height_diff', 'weight_diff', 'reach_diff', 'SLpM_total_diff',\n",
      "       'SApM_total_diff', 'sig_str_acc_total_diff', 'td_acc_total_diff',\n",
      "       'str_def_total_diff', 'td_def_total_diff', 'sub_avg_diff',\n",
      "       'td_avg_diff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ufc_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77fa0b91-0d93-4671-8de8-32dcc11f44fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/vadim/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages (from imbalanced-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/vadim/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages (from imbalanced-learn) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/vadim/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/vadim/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vadim/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39a8f9-d289-44f3-b6ef-cc8e083b7e9d",
   "metadata": {},
   "source": [
    "## Data Preparation, Model Training, and Evaluation with Class Balancing and Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ecac7-6560-43e8-af82-ef9cfb963ada",
   "metadata": {},
   "source": [
    "This code involves loading and preprocessing UFC fight data, including filling missing values, creating corner-independent features, and encoding categorical variables. The dataset is balanced using SMOTE to address class imbalance, and features are standardized to prevent dominance by any specific feature. The data is split into training and testing sets, after which three models (Logistic Regression, Random Forest, and XGBoost) are trained, calibrated, and evaluated based on accuracy and classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903f4ff5-2a65-4c50-b593-3b0ba4a6bf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.8713480266529985\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.89      0.88       991\n",
      "        True       0.89      0.85      0.87       960\n",
      "\n",
      "    accuracy                           0.87      1951\n",
      "   macro avg       0.87      0.87      0.87      1951\n",
      "weighted avg       0.87      0.87      0.87      1951\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9144028703229113\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.93      0.92       991\n",
      "        True       0.92      0.90      0.91       960\n",
      "\n",
      "    accuracy                           0.91      1951\n",
      "   macro avg       0.91      0.91      0.91      1951\n",
      "weighted avg       0.91      0.91      0.91      1951\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.9287544848795489\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.93      0.93       991\n",
      "        True       0.93      0.93      0.93       960\n",
      "\n",
      "    accuracy                           0.93      1951\n",
      "   macro avg       0.93      0.93      0.93      1951\n",
      "weighted avg       0.93      0.93      0.93      1951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Step 1: Load data\n",
    "ufc_data = pd.read_csv('../data/processed/ufc_fight_data_cleaned.csv')\n",
    "\n",
    "# Step 2: Fill missing values\n",
    "numeric_columns = ufc_data.select_dtypes(include=['number']).columns\n",
    "ufc_data[numeric_columns] = ufc_data[numeric_columns].fillna(ufc_data[numeric_columns].mean())\n",
    "categorical_columns = ufc_data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    ufc_data[column].fillna(ufc_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Step 3: Feature Engineering - Create Corner-Independent Features\n",
    "ufc_data['kd_diff'] = abs(ufc_data['r_kd'] - ufc_data['b_kd'])\n",
    "ufc_data['sig_str_diff'] = abs(ufc_data['r_sig_str'] - ufc_data['b_sig_str'])\n",
    "ufc_data['td_diff'] = abs(ufc_data['r_td'] - ufc_data['b_td'])\n",
    "ufc_data['kd_ratio'] = ufc_data['r_kd'] / (ufc_data['b_kd'] + 1e-5)\n",
    "ufc_data['sig_str_ratio'] = ufc_data['r_sig_str'] / (ufc_data['b_sig_str'] + 1e-5)\n",
    "ufc_data['td_ratio'] = ufc_data['r_td'] / (ufc_data['b_td'] + 1e-5)\n",
    "\n",
    "# Specify which columns to drop and avoid dropping 'r_fighter' and 'b_fighter'\n",
    "features_to_drop = [col for col in ufc_data.columns if col.startswith(('r_', 'b_')) and col not in ['r_fighter', 'b_fighter']]\n",
    "ufc_data = ufc_data.drop(columns=features_to_drop)\n",
    "\n",
    "# Step 4: Encode categorical variables\n",
    "ufc_data_encoded = pd.get_dummies(ufc_data, drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = ufc_data_encoded.drop(columns=['winner_Red'])\n",
    "y = ufc_data_encoded['winner_Red']\n",
    "\n",
    "# Step 5: Handle Imbalance in the Data with SMOTE\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Step 6: Standardize features to avoid dominance of any specific feature\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train, calibrate, and evaluate each model\n",
    "def train_and_evaluate_model(model, model_name):\n",
    "    if model_name in [\"Random Forest\", \"XGBoost\"]:\n",
    "        model = CalibratedClassifierCV(estimator=model, method='sigmoid', cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return model  # Return the fitted model\n",
    "\n",
    "# Initialize and evaluate models\n",
    "log_reg_model = LogisticRegression(class_weight='balanced', max_iter=2000, solver='saga', random_state=42)\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "xgb_model = XGBClassifier(scale_pos_weight=(y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]), eval_metric='logloss')\n",
    "\n",
    "# Train and evaluate models\n",
    "log_reg_model = train_and_evaluate_model(log_reg_model, \"Logistic Regression\")\n",
    "rf_model = train_and_evaluate_model(rf_model, \"Random Forest\")\n",
    "xgb_model = train_and_evaluate_model(xgb_model, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f980e1-4dcb-4bd8-af16-dd89f1616c97",
   "metadata": {},
   "source": [
    "## Fight Outcome Prediction for Specific Fighters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbbe63e-bab0-486b-9c60-22c3996e95a1",
   "metadata": {},
   "source": [
    "This code includes a function for preparing data and predicting fight outcomes between two fighters. The `prepare_fight_data` function calculates absolute differences and ratio-based features for key characteristics of each fighter, creating test data aligned with the training features. This data is scaled and fed into trained models (Logistic Regression, Random Forest, and XGBoost) to predict the fight winner. A prediction example is provided for fights between Islam Makhachev and Dustin Poirier, with reversed roles (Red and Blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5b0be4b-8bb8-47c4-a453-4e96fee80c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction: Red (Islam Makhachev)\n",
      "Random Forest Prediction: Red (Islam Makhachev)\n",
      "XGBoost Prediction: Red (Islam Makhachev)\n"
     ]
    }
   ],
   "source": [
    "# Prediction example for a specific fight\n",
    "def prepare_fight_data(df, r_fighter_name, b_fighter_name):\n",
    "    # Select relevant rows for each fighter\n",
    "    r_fighter_data = df[df['r_fighter'] == r_fighter_name]\n",
    "    b_fighter_data = df[df['b_fighter'] == b_fighter_name]\n",
    "    if not r_fighter_data.empty and not b_fighter_data.empty:\n",
    "        r_avg = r_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        b_avg = b_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        # Create absolute difference and ratio-based test data\n",
    "        test_data = pd.DataFrame({\n",
    "            'kd_diff': [abs(r_avg.get('kd_diff', 0) - b_avg.get('kd_diff', 0))],\n",
    "            'sig_str_diff': [abs(r_avg.get('sig_str_diff', 0) - b_avg.get('sig_str_diff', 0))],\n",
    "            'td_diff': [abs(r_avg.get('td_diff', 0) - b_avg.get('td_diff', 0))],\n",
    "            'kd_ratio': [r_avg.get('kd_diff', 1) / (b_avg.get('kd_diff', 1) + 1e-5)],\n",
    "            'sig_str_ratio': [r_avg.get('sig_str_diff', 1) / (b_avg.get('sig_str_diff', 1) + 1e-5)],\n",
    "            'td_ratio': [r_avg.get('td_diff', 1) / (b_avg.get('td_diff', 1) + 1e-5)]\n",
    "        })\n",
    "        \n",
    "        # Align with training features and scale\n",
    "        test_data_aligned = test_data.reindex(columns=X_train.columns, fill_value=0)\n",
    "        test_data_scaled = pd.DataFrame(scaler.transform(test_data_aligned), columns=X_train.columns)\n",
    "        \n",
    "        return test_data_scaled\n",
    "\n",
    "    return None\n",
    "\n",
    "# Test prediction for Islam Makhachev vs Dustin Poirier\n",
    "test_data_encoded = prepare_fight_data(ufc_data, 'Islam Makhachev', 'Dustin Poirier')\n",
    "if test_data_encoded is not None:\n",
    "    for model, name in zip([log_reg_model, rf_model, xgb_model], [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]):\n",
    "        try:\n",
    "            prediction = model.predict(test_data_encoded)\n",
    "            result = \"Red (Islam Makhachev)\" if prediction[0] else \"Blue (Dustin Poirier)\"\n",
    "            print(f\"{name} Prediction: {result}\")\n",
    "        except NotFittedError:\n",
    "            print(f\"{name} model is not fitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0ca19-be2d-453e-82f1-a3a7136a105c",
   "metadata": {},
   "source": [
    "## Additional Check with Switched Fighter Corners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064206d-2938-4b56-929c-0adb37ff2fc0",
   "metadata": {},
   "source": [
    " This code provides an additional check by switching fighter roles in the corners, with Dustin Poirier now in the red corner and Islam Makhachev in the blue corner. The `prepare_fight_data` function prepares the fight data accordingly. Predictions are made using the three trained models (Logistic Regression, Random Forest, and XGBoost), and the outcome for the winner is printed. This approach helps evaluate the effect of role switching on prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a667a81-9928-4a08-8412-60f9db0175b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction: Red (Dustin Poirier)\n",
      "Random Forest Prediction: Red (Dustin Poirier)\n",
      "XGBoost Prediction: Red (Dustin Poirier)\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for Dustin Poirier vs Islam Makhachev (reversed roles)\n",
    "test_data_encoded = prepare_fight_data(ufc_data, 'Dustin Poirier', 'Islam Makhachev')\n",
    "if test_data_encoded is not None:\n",
    "    for model, name in zip([log_reg_model, rf_model, xgb_model], [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]):\n",
    "        try:\n",
    "            prediction = model.predict(test_data_encoded)\n",
    "            result = \"Red (Dustin Poirier)\" if prediction[0] else \"Blue (Islam Makhachev)\"\n",
    "            print(f\"{name} Prediction: {result}\")\n",
    "        except NotFittedError:\n",
    "            print(f\"{name} model is not fitted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4f355-d20f-4d98-8296-dd1ce7c7d9cc",
   "metadata": {},
   "source": [
    "## Model Training and Fight Outcome Prediction with Enhanced Features and Class Balancing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb2383-84e9-49c9-b752-77220a3a65e8",
   "metadata": {},
   "source": [
    "This code fully prepares and trains models for predicting UFC fight outcomes. Data is preprocessed to fill missing values, enhanced features like difference and ratio of fighter statistics are added, and class imbalance is addressed using SMOTE. The data is then standardized, and models (Logistic Regression, Random Forest, and XGBoost) are trained and calibrated to improve predictive accuracy. The prediction function `prepare_fight_data` prepares data for specific fighters using the selected features. Additional predictions are made by swapping corner assignments (Red and Blue) for Islam Makhachev and Dustin Poirier to assess the impact of corner assignments on prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0474a8e4-f3f6-46d3-8738-44a085f27a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.8749359302921579\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.90      0.88       991\n",
      "        True       0.89      0.85      0.87       960\n",
      "\n",
      "    accuracy                           0.87      1951\n",
      "   macro avg       0.88      0.87      0.87      1951\n",
      "weighted avg       0.88      0.87      0.87      1951\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9072270630445926\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.92      0.91       991\n",
      "        True       0.91      0.90      0.90       960\n",
      "\n",
      "    accuracy                           0.91      1951\n",
      "   macro avg       0.91      0.91      0.91      1951\n",
      "weighted avg       0.91      0.91      0.91      1951\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.9323423885187083\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.93      0.93       991\n",
      "        True       0.93      0.93      0.93       960\n",
      "\n",
      "    accuracy                           0.93      1951\n",
      "   macro avg       0.93      0.93      0.93      1951\n",
      "weighted avg       0.93      0.93      0.93      1951\n",
      "\n",
      "\n",
      "Testing Islam Makhachev (Red) vs Dustin Poirier (Blue)\n",
      "Logistic Regression Prediction: Winner: Red (Islam Makhachev)\n",
      "Random Forest Prediction: Winner: Red (Islam Makhachev)\n",
      "XGBoost Prediction: Winner: Red (Islam Makhachev)\n",
      "\n",
      "Testing Dustin Poirier (Red) vs Islam Makhachev (Blue)\n",
      "Logistic Regression Prediction: Winner: Red (Dustin Poirier)\n",
      "Random Forest Prediction: Winner: Red (Dustin Poirier)\n",
      "XGBoost Prediction: Winner: Red (Dustin Poirier)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Step 1: Load data\n",
    "ufc_data = pd.read_csv('../data/processed/ufc_fight_data_cleaned.csv')\n",
    "\n",
    "# Step 2: Fill missing values\n",
    "numeric_columns = ufc_data.select_dtypes(include=['number']).columns\n",
    "ufc_data[numeric_columns] = ufc_data[numeric_columns].fillna(ufc_data[numeric_columns].mean())\n",
    "categorical_columns = ufc_data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    ufc_data[column].fillna(ufc_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Step 3: Feature Engineering - Enhanced Features\n",
    "ufc_data['kd_diff'] = ufc_data['r_kd'] - ufc_data['b_kd']\n",
    "ufc_data['sig_str_diff'] = ufc_data['r_sig_str'] - ufc_data['b_sig_str']\n",
    "ufc_data['td_diff'] = ufc_data['r_td'] - ufc_data['b_td']\n",
    "ufc_data['kd_ratio'] = ufc_data['r_kd'] / (ufc_data['b_kd'] + 1e-5)\n",
    "ufc_data['sig_str_ratio'] = ufc_data['r_sig_str'] / (ufc_data['b_sig_str'] + 1e-5)\n",
    "ufc_data['td_ratio'] = ufc_data['r_td'] / (ufc_data['b_td'] + 1e-5)\n",
    "ufc_data['total_str_diff'] = (ufc_data['r_sig_str'] + ufc_data['r_str']) - (ufc_data['b_sig_str'] + ufc_data['b_str'])\n",
    "\n",
    "# Drop original corner-specific columns\n",
    "features_to_drop = [col for col in ufc_data.columns if col.startswith(('r_', 'b_')) and col not in ['r_fighter', 'b_fighter']]\n",
    "ufc_data = ufc_data.drop(columns=features_to_drop)\n",
    "\n",
    "# Step 4: Encode categorical variables\n",
    "ufc_data_encoded = pd.get_dummies(ufc_data, drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = ufc_data_encoded.drop(columns=['winner_Red'])\n",
    "y = ufc_data_encoded['winner_Red']\n",
    "\n",
    "# Step 5: Handle Imbalance with SMOTE\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Step 6: Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training function\n",
    "def train_and_evaluate_model(model, model_name):\n",
    "    if model_name in [\"Random Forest\", \"XGBoost\"]:\n",
    "        model = CalibratedClassifierCV(estimator=model, method='sigmoid', cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize models\n",
    "log_reg_model = LogisticRegression(class_weight='balanced', max_iter=2000, solver='saga', random_state=42)\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "xgb_model = XGBClassifier(scale_pos_weight=(y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]), eval_metric='logloss')\n",
    "\n",
    "# Train and evaluate models\n",
    "log_reg_model = train_and_evaluate_model(log_reg_model, \"Logistic Regression\")\n",
    "rf_model = train_and_evaluate_model(rf_model, \"Random Forest\")\n",
    "xgb_model = train_and_evaluate_model(xgb_model, \"XGBoost\")\n",
    "\n",
    "# Prediction function with balanced features for fighters\n",
    "def prepare_fight_data(df, r_fighter_name, b_fighter_name):\n",
    "    r_fighter_data = df[df['r_fighter'] == r_fighter_name]\n",
    "    b_fighter_data = df[df['b_fighter'] == b_fighter_name]\n",
    "    if not r_fighter_data.empty and not b_fighter_data.empty:\n",
    "        r_avg = r_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        b_avg = b_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        test_data = pd.DataFrame({\n",
    "            'kd_diff': [r_avg.get('kd_diff', 0) - b_avg.get('kd_diff', 0)],\n",
    "            'sig_str_diff': [r_avg.get('sig_str_diff', 0) - b_avg.get('sig_str_diff', 0)],\n",
    "            'td_diff': [r_avg.get('td_diff', 0) - b_avg.get('td_diff', 0)],\n",
    "            'kd_ratio': [r_avg.get('kd_diff', 1) / (b_avg.get('kd_diff', 1) + 1e-5)],\n",
    "            'sig_str_ratio': [r_avg.get('sig_str_diff', 1) / (b_avg.get('sig_str_diff', 1) + 1e-5)],\n",
    "            'td_ratio': [r_avg.get('td_diff', 1) / (b_avg.get('td_diff', 1) + 1e-5)],\n",
    "            'total_str_diff': [(r_avg.get('sig_str_diff', 0) + r_avg.get('str_diff', 0)) - (b_avg.get('sig_str_diff', 0) + b_avg.get('str_diff', 0))]\n",
    "        })\n",
    "        test_data_aligned = test_data.reindex(columns=X_train.columns, fill_value=0)\n",
    "        test_data_scaled = pd.DataFrame(scaler.transform(test_data_aligned), columns=X_train.columns)\n",
    "        \n",
    "        return test_data_scaled\n",
    "\n",
    "# Test with fighters swapped\n",
    "for r_fighter, b_fighter in [('Islam Makhachev', 'Dustin Poirier'), ('Dustin Poirier', 'Islam Makhachev')]:\n",
    "    print(f\"\\nTesting {r_fighter} (Red) vs {b_fighter} (Blue)\")\n",
    "    test_data_encoded = prepare_fight_data(ufc_data, r_fighter, b_fighter)\n",
    "    if test_data_encoded is not None:\n",
    "        for model, name in zip([log_reg_model, rf_model, xgb_model], [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]):\n",
    "            try:\n",
    "                prediction = model.predict(test_data_encoded)\n",
    "                result = f\"Winner: {'Red' if prediction[0] else 'Blue'} ({r_fighter if prediction[0] else b_fighter})\"\n",
    "                print(f\"{name} Prediction: {result}\")\n",
    "            except NotFittedError:\n",
    "                print(f\"{name} model is not fitted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20994806-a155-4c80-b289-1e896cde5954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event_name', 'date', 'location', 'r_fighter', 'b_fighter', 'winner', 'weight_class', 'is_title_bout', 'gender', 'method', 'finish_round', 'total_rounds', 'time_sec', 'referee', 'r_kd', 'r_sig_str', 'r_sig_str_att', 'r_sig_str_acc', 'r_str', 'r_str_att', 'r_str_acc', 'r_td', 'r_td_att', 'r_td_acc', 'r_sub_att', 'r_rev', 'r_ctrl_sec', 'r_wins_total', 'r_losses_total', 'r_age', 'r_height', 'r_weight', 'r_reach', 'r_stance', 'r_SLpM_total', 'r_SApM_total', 'r_sig_str_acc_total', 'r_td_acc_total', 'r_str_def_total', 'r_td_def_total', 'r_sub_avg', 'r_td_avg', 'b_kd', 'b_sig_str', 'b_sig_str_att', 'b_sig_str_acc', 'b_str', 'b_str_att', 'b_str_acc', 'b_td', 'b_td_att', 'b_td_acc', 'b_sub_att', 'b_rev', 'b_ctrl_sec', 'b_wins_total', 'b_losses_total', 'b_age', 'b_height', 'b_weight', 'b_reach', 'b_stance', 'b_SLpM_total', 'b_SApM_total', 'b_sig_str_acc_total', 'b_td_acc_total', 'b_str_def_total', 'b_td_def_total', 'b_sub_avg', 'b_td_avg', 'kd_diff', 'sig_str_diff', 'sig_str_att_diff', 'sig_str_acc_diff', 'str_diff', 'str_att_diff', 'str_acc_diff', 'td_diff', 'td_att_diff', 'td_acc_diff', 'sub_att_diff', 'rev_diff', 'ctrl_sec_diff', 'wins_total_diff', 'losses_total_diff', 'age_diff', 'height_diff', 'weight_diff', 'reach_diff', 'SLpM_total_diff', 'SApM_total_diff', 'sig_str_acc_total_diff', 'td_acc_total_diff', 'str_def_total_diff', 'td_def_total_diff', 'sub_avg_diff', 'td_avg_diff', 'kd_ratio', 'sig_str_ratio', 'td_ratio', 'total_str_diff']\n"
     ]
    }
   ],
   "source": [
    "# To display all column names in your DataFrame\n",
    "print(ufc_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0176bf-80c4-49c2-b5d7-558461c569b1",
   "metadata": {},
   "source": [
    "## Advanced Fight Outcome Predictions Using Corner-Independent Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f15dd6-db3f-4190-81a3-896434500ca5",
   "metadata": {},
   "source": [
    "This code performs advanced predictions of UFC fight outcomes using an extended set of features calculated as differences and ratios between fighters' statistics. Data preprocessing includes filling missing values, feature engineering for corner-independent fighter characteristics, class balancing with SMOTE, and feature standardization. After data splitting, models (Logistic Regression, Random Forest, and XGBoost) are trained and calibrated for accurate predictions. The `prepare_fight_data` function prepares data for two fighters, aligning it with training data features. Prediction examples are provided for fights between Islam Makhachev and Dustin Poirier with reversed roles (Red and Blue) to assess the impact of corner assignments on the fight outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9d341c7-e431-45d5-a29b-5ef64b279a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.8918503331624807\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90       991\n",
      "        True       0.90      0.87      0.89       960\n",
      "\n",
      "    accuracy                           0.89      1951\n",
      "   macro avg       0.89      0.89      0.89      1951\n",
      "weighted avg       0.89      0.89      0.89      1951\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9195284469502819\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.93      0.92       991\n",
      "        True       0.92      0.91      0.92       960\n",
      "\n",
      "    accuracy                           0.92      1951\n",
      "   macro avg       0.92      0.92      0.92      1951\n",
      "weighted avg       0.92      0.92      0.92      1951\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.9359302921578677\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.94      0.94       991\n",
      "        True       0.94      0.93      0.93       960\n",
      "\n",
      "    accuracy                           0.94      1951\n",
      "   macro avg       0.94      0.94      0.94      1951\n",
      "weighted avg       0.94      0.94      0.94      1951\n",
      "\n",
      "Testing Islam Makhachev (Red) vs Dustin Poirier (Blue)\n",
      "Logistic Regression Prediction: Winner: Red (Islam Makhachev)\n",
      "Random Forest Prediction: Winner: Red (Islam Makhachev)\n",
      "XGBoost Prediction: Winner: Red (Islam Makhachev)\n",
      "\n",
      "Testing Dustin Poirier (Red) vs Islam Makhachev (Blue)\n",
      "Logistic Regression Prediction: Winner: Red (Dustin Poirier)\n",
      "Random Forest Prediction: Winner: Red (Dustin Poirier)\n",
      "XGBoost Prediction: Winner: Red (Dustin Poirier)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Step 1: Load data\n",
    "ufc_data = pd.read_csv('../data/processed/ufc_fight_data_cleaned.csv')\n",
    "\n",
    "# Step 2: Fill missing values\n",
    "numeric_columns = ufc_data.select_dtypes(include=['number']).columns\n",
    "ufc_data[numeric_columns] = ufc_data[numeric_columns].fillna(ufc_data[numeric_columns].mean())\n",
    "categorical_columns = ufc_data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    ufc_data[column].fillna(ufc_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Step 3: Feature Engineering - Calculate Corner-Independent Features\n",
    "feature_cols = [\n",
    "    'kd_diff', 'sig_str_diff', 'sig_str_att_diff', 'sig_str_acc_diff', 'str_diff',\n",
    "    'str_att_diff', 'str_acc_diff', 'td_diff', 'td_att_diff', 'td_acc_diff', 'sub_att_diff',\n",
    "    'rev_diff', 'ctrl_sec_diff', 'wins_total_diff', 'losses_total_diff', 'age_diff',\n",
    "    'height_diff', 'weight_diff', 'reach_diff', 'SLpM_total_diff', 'SApM_total_diff',\n",
    "    'sig_str_acc_total_diff', 'td_acc_total_diff', 'str_def_total_diff', 'td_def_total_diff',\n",
    "    'sub_avg_diff', 'td_avg_diff', 'kd_ratio', 'sig_str_ratio', 'td_ratio', 'total_str_diff'\n",
    "]\n",
    "\n",
    "# Ensure required columns are in DataFrame\n",
    "for col in feature_cols:\n",
    "    if col not in ufc_data.columns:\n",
    "        ufc_data[col] = 0  # Handle missing columns if necessary\n",
    "\n",
    "# Step 4: Encode categorical variables\n",
    "ufc_data_encoded = pd.get_dummies(ufc_data, drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = ufc_data_encoded.drop(columns=['winner_Red'])\n",
    "y = ufc_data_encoded['winner_Red']\n",
    "\n",
    "# Step 5: Handle Imbalance in the Data with SMOTE\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Step 6: Standardize features to avoid dominance of any specific feature\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train, calibrate, and evaluate each model\n",
    "def train_and_evaluate_model(model, model_name):\n",
    "    if model_name in [\"Random Forest\", \"XGBoost\"]:\n",
    "        model = CalibratedClassifierCV(estimator=model, method='sigmoid', cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return model  # Return the fitted model\n",
    "\n",
    "# Initialize and evaluate models\n",
    "log_reg_model = LogisticRegression(class_weight='balanced', max_iter=2000, solver='saga', random_state=42)\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "xgb_model = XGBClassifier(scale_pos_weight=(y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]), eval_metric='logloss')\n",
    "\n",
    "# Train and evaluate models\n",
    "log_reg_model = train_and_evaluate_model(log_reg_model, \"Logistic Regression\")\n",
    "rf_model = train_and_evaluate_model(rf_model, \"Random Forest\")\n",
    "xgb_model = train_and_evaluate_model(xgb_model, \"XGBoost\")\n",
    "\n",
    "# Prediction example for a specific fight with all feature columns\n",
    "def prepare_fight_data(df, r_fighter_name, b_fighter_name):\n",
    "    # Select relevant rows for each fighter\n",
    "    r_fighter_data = df[df['r_fighter'] == r_fighter_name]\n",
    "    b_fighter_data = df[df['b_fighter'] == b_fighter_name]\n",
    "    if not r_fighter_data.empty and not b_fighter_data.empty:\n",
    "        r_avg = r_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        b_avg = b_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        \n",
    "        # Prepare all specified features for prediction\n",
    "        test_data = pd.DataFrame({feature: [abs(r_avg.get(feature, 0) - b_avg.get(feature, 0))] for feature in feature_cols})\n",
    "        \n",
    "        # Align with training features and scale\n",
    "        test_data_aligned = test_data.reindex(columns=X_train.columns, fill_value=0)\n",
    "        test_data_scaled = pd.DataFrame(scaler.transform(test_data_aligned), columns=X_train.columns)\n",
    "        \n",
    "        return test_data_scaled\n",
    "\n",
    "    return None\n",
    "\n",
    "# Test prediction for Islam Makhachev vs Dustin Poirier\n",
    "print(\"Testing Islam Makhachev (Red) vs Dustin Poirier (Blue)\")\n",
    "test_data_1 = prepare_fight_data(ufc_data, 'Islam Makhachev', 'Dustin Poirier')\n",
    "if test_data_1 is not None:\n",
    "    for model, name in zip([log_reg_model, rf_model, xgb_model], [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]):\n",
    "        prediction = model.predict(test_data_1)\n",
    "        result = \"Red (Islam Makhachev)\" if prediction[0] else \"Blue (Dustin Poirier)\"\n",
    "        print(f\"{name} Prediction: Winner: {result}\")\n",
    "\n",
    "print(\"\\nTesting Dustin Poirier (Red) vs Islam Makhachev (Blue)\")\n",
    "test_data_2 = prepare_fight_data(ufc_data, 'Dustin Poirier', 'Islam Makhachev')\n",
    "if test_data_2 is not None:\n",
    "    for model, name in zip([log_reg_model, rf_model, xgb_model], [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]):\n",
    "        prediction = model.predict(test_data_2)\n",
    "        result = \"Red (Dustin Poirier)\" if prediction[0] else \"Blue (Islam Makhachev)\"\n",
    "        print(f\"{name} Prediction: Winner: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b9066-683c-4010-b7d3-31c1a3ab30a6",
   "metadata": {},
   "source": [
    "## UFC Fight Outcome Prediction with Difference and Ratio-Based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b1044-5216-43ab-ba0d-c5dfae2347dc",
   "metadata": {},
   "source": [
    "This code performs UFC fight outcome predictions using machine learning models with features that are independent of fighter corners. The initial steps load and preprocess the data to fill missing values and calculate new features based on differences and ratios between fighters' statistics. The data is balanced with SMOTE to address class imbalance and standardized for consistency. Models (Logistic Regression, Random Forest, and XGBoost) are trained and calibrated for improved predictive accuracy. The `prepare_fight_data` function prepares data for two fighters by calculating relevant features, which are then fed into the models to predict fight outcomes. Examples of predictions are provided for fights between Islam Makhachev and Dustin Poirier with alternating corner assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad0ae78d-4517-4063-9866-0e0751d81b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.8856996412096361\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.91      0.89       991\n",
      "        True       0.90      0.87      0.88       960\n",
      "\n",
      "    accuracy                           0.89      1951\n",
      "   macro avg       0.89      0.89      0.89      1951\n",
      "weighted avg       0.89      0.89      0.89      1951\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9082521783700667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.92      0.91       991\n",
      "        True       0.91      0.90      0.91       960\n",
      "\n",
      "    accuracy                           0.91      1951\n",
      "   macro avg       0.91      0.91      0.91      1951\n",
      "weighted avg       0.91      0.91      0.91      1951\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.9343926191696565\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.94      0.94       991\n",
      "        True       0.94      0.93      0.93       960\n",
      "\n",
      "    accuracy                           0.93      1951\n",
      "   macro avg       0.93      0.93      0.93      1951\n",
      "weighted avg       0.93      0.93      0.93      1951\n",
      "\n",
      "Testing Islam Makhachev (Red) vs Dustin Poirier (Blue)\n",
      "Logistic Regression Prediction: Winner: Red (Islam Makhachev)\n",
      "Random Forest Prediction: Winner: Red (Islam Makhachev)\n",
      "XGBoost Prediction: Winner: Red (Islam Makhachev)\n",
      "\n",
      "Testing Dustin Poirier (Red) vs Islam Makhachev (Blue)\n",
      "Logistic Regression Prediction: Winner: Red (Dustin Poirier)\n",
      "Random Forest Prediction: Winner: Red (Dustin Poirier)\n",
      "XGBoost Prediction: Winner: Red (Dustin Poirier)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load data\n",
    "ufc_data = pd.read_csv('../data/processed/ufc_fight_data_cleaned.csv')\n",
    "\n",
    "# Step 2: Fill missing values\n",
    "numeric_columns = ufc_data.select_dtypes(include=['number']).columns\n",
    "ufc_data[numeric_columns] = ufc_data[numeric_columns].fillna(ufc_data[numeric_columns].mean())\n",
    "categorical_columns = ufc_data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    ufc_data[column].fillna(ufc_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Step 3: Feature Engineering - Create Corner-Independent Features\n",
    "feature_list = [\n",
    "    'kd', 'sig_str', 'sig_str_att', 'sig_str_acc', 'str', 'str_att', 'str_acc', 'td', \n",
    "    'td_att', 'td_acc', 'sub_att', 'rev', 'ctrl_sec', 'wins_total', 'losses_total', \n",
    "    'age', 'height', 'weight', 'reach', 'SLpM_total', 'SApM_total', 'sig_str_acc_total', \n",
    "    'td_acc_total', 'str_def_total', 'td_def_total', 'sub_avg', 'td_avg'\n",
    "]\n",
    "\n",
    "# Generate diff and ratio features in one step for better performance\n",
    "diff_features = pd.DataFrame()\n",
    "ratio_features = pd.DataFrame()\n",
    "\n",
    "for feature in feature_list:\n",
    "    diff_features[f'{feature}_diff'] = abs(ufc_data[f'r_{feature}'] - ufc_data[f'b_{feature}'])\n",
    "    ratio_features[f'{feature}_ratio'] = ufc_data[f'r_{feature}'] / (ufc_data[f'b_{feature}'] + 1e-5)\n",
    "\n",
    "# Concatenate new features with the original DataFrame\n",
    "ufc_data = pd.concat([ufc_data, diff_features, ratio_features], axis=1)\n",
    "\n",
    "# Drop original `r_` and `b_` features after creating difference and ratio features\n",
    "features_to_drop = [f'r_{feature}' for feature in feature_list] + [f'b_{feature}' for feature in feature_list]\n",
    "ufc_data = ufc_data.drop(columns=features_to_drop)\n",
    "\n",
    "# Step 4: Encode categorical variables\n",
    "ufc_data_encoded = pd.get_dummies(ufc_data, drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = ufc_data_encoded.drop(columns=['winner_Red'])\n",
    "y = ufc_data_encoded['winner_Red']\n",
    "\n",
    "# Step 5: Handle Imbalance in the Data with SMOTE\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Step 6: Standardize features to avoid dominance of any specific feature\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train, calibrate, and evaluate each model\n",
    "def train_and_evaluate_model(model, model_name):\n",
    "    if model_name in [\"Random Forest\", \"XGBoost\"]:\n",
    "        model = CalibratedClassifierCV(estimator=model, method='sigmoid', cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return model  # Return the fitted model\n",
    "\n",
    "# Initialize and evaluate models\n",
    "log_reg_model = LogisticRegression(class_weight='balanced', max_iter=2000, solver='saga', random_state=42)\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "xgb_model = XGBClassifier(scale_pos_weight=(y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]), eval_metric='logloss')\n",
    "\n",
    "# Train and evaluate models\n",
    "log_reg_model = train_and_evaluate_model(log_reg_model, \"Logistic Regression\")\n",
    "rf_model = train_and_evaluate_model(rf_model, \"Random Forest\")\n",
    "xgb_model = train_and_evaluate_model(xgb_model, \"XGBoost\")\n",
    "\n",
    "# Test prediction function and predictions\n",
    "def prepare_fight_data(df, r_fighter_name, b_fighter_name):\n",
    "    # Select relevant rows for each fighter\n",
    "    r_fighter_data = df[df['r_fighter'] == r_fighter_name]\n",
    "    b_fighter_data = df[df['b_fighter'] == b_fighter_name]\n",
    "    if not r_fighter_data.empty and not b_fighter_data.empty:\n",
    "        r_avg = r_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        b_avg = b_fighter_data.select_dtypes(include=['number']).mean()\n",
    "        \n",
    "        # Prepare diff and ratio features for prediction\n",
    "        test_data = {f'{feature}_diff': [abs(r_avg.get(f'r_{feature}', 0) - b_avg.get(f'b_{feature}', 0))] for feature in feature_list}\n",
    "        test_data.update({f'{feature}_ratio': [r_avg.get(f'r_{feature}', 1) / (b_avg.get(f'b_{feature}', 1) + 1e-5)] for feature in feature_list})\n",
    "        \n",
    "        # Convert dictionary to DataFrame and align with training features\n",
    "        test_data_df = pd.DataFrame(test_data)\n",
    "        test_data_aligned = test_data_df.reindex(columns=X.columns, fill_value=0)\n",
    "        \n",
    "        # Scale the test data\n",
    "        test_data_scaled = scaler.transform(test_data_aligned)\n",
    "        \n",
    "        return test_data_scaled\n",
    "\n",
    "    return None\n",
    "\n",
    "# Test predictions\n",
    "print(\"Testing Islam Makhachev (Red) vs Dustin Poirier (Blue)\")\n",
    "test_data_1 = prepare_fight_data(ufc_data, 'Islam Makhachev', 'Dustin Poirier')\n",
    "if test_data_1 is not None:\n",
    "    for model, name in zip([log_reg_model, rf_model, xgb_model], [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]):\n",
    "        prediction = model.predict(test_data_1)\n",
    "        result = \"Red (Islam Makhachev)\" if prediction[0] else \"Blue (Dustin Poirier)\"\n",
    "        print(f\"{name} Prediction: Winner: {result}\")\n",
    "\n",
    "print(\"\\nTesting Dustin Poirier (Red) vs Islam Makhachev (Blue)\")\n",
    "test_data_2 = prepare_fight_data(ufc_data, 'Dustin Poirier', 'Islam Makhachev')\n",
    "if test_data_2 is not None:\n",
    "    for model, name in zip([log_reg_model, rf_model, xgb_model], [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]):\n",
    "        prediction = model.predict(test_data_2)\n",
    "        result = \"Red (Dustin Poirier)\" if prediction[0] else \"Blue (Islam Makhachev)\"\n",
    "        print(f\"{name} Prediction: Winner: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3455c960-8af8-499e-8e19-4890fbab4de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.2-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /Users/vadim/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in /Users/vadim/BachelorThesis/SportiNetAI/.venv/lib/python3.11/site-packages (from xgboost) (1.11.2)\n",
      "Downloading xgboost-2.1.2-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6509ad8-90f7-4007-8c79-05a49183dbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SportiNetAI)",
   "language": "python",
   "name": "sportinetai_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
