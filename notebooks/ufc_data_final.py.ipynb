{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# # Project: UFC Fight Data Processing",
   "id": "bd1bbddfb3e424ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### This file processes UFC fight data by:\n",
    "\n",
    "- Performing an initial analysis of multiple datasets.\n",
    "- Selecting and merging key datasets.\n",
    "- Cleaning the data: removing duplicates, handling missing values, and standardizing columns.\n",
    "- Producing a final dataset containing detailed information about events and fighters.\n"
   ],
   "id": "dff8b43b3ab54598"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### # Load Datasets\n",
    "**Description**:  \n",
    "Load all datasets containing information about events and fighters."
   ],
   "id": "271f55a11f6f84e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:37.879919Z",
     "start_time": "2024-12-22T19:25:37.876516Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "fe08726a34ead9cc",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.041883Z",
     "start_time": "2024-12-22T19:25:37.929238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load all datasets\n",
    "fighter_stats = pd.read_csv('../data/raw/Fighter_stats/fighter_stats.csv')\n",
    "large_dataset = pd.read_csv('../data/raw/Large_set/large_dataset.csv')\n",
    "medium_dataset = pd.read_csv('../data/raw/Medium_set/medium_dataset.csv')\n",
    "ufc = pd.read_csv('../data/raw/ufc.csv')\n",
    "ufc_master = pd.read_csv('../data/raw/ufc-master.csv')\n",
    "completed_events_small = pd.read_csv('../data/raw/Small_set/completed_events_small.csv')"
   ],
   "id": "4ae4920a4fed4d43",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### # Display Columns for All Datasets\n",
    " **Description**:  \n",
    "Display the column names of all datasets to understand their structure."
   ],
   "id": "b17f40455d12232f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.074184Z",
     "start_time": "2024-12-22T19:25:38.071708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to print dataset columns\n",
    "def print_dataset_columns(df, df_name):\n",
    "    print(f\"\\n=== Columns in {df_name} ===\")\n",
    "    print(df.columns.tolist())\n",
    "    print(f\"Total Columns: {len(df.columns)}\")\n",
    "\n",
    "# Display columns for all datasets\n",
    "print_dataset_columns(fighter_stats, \"Fighter Stats\")\n",
    "print_dataset_columns(large_dataset, \"Large Dataset\")\n",
    "print_dataset_columns(medium_dataset, \"Medium Dataset\")\n",
    "print_dataset_columns(ufc, \"UFC Dataset\")\n",
    "print_dataset_columns(ufc_master, \"UFC Master Dataset\")\n",
    "print_dataset_columns(completed_events_small, \"Completed Events Small Dataset\")\n",
    "\n",
    "# Explanation of chosen datasets\n",
    "print(\"\\nFrom the above datasets, we selected:\")\n",
    "print(\"- Large Dataset: for detailed fight information, including event names and fighters.\")\n",
    "print(\"- Medium Dataset: for additional event metadata, such as dates and locations.\")"
   ],
   "id": "ae63e035212734e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Columns in Fighter Stats ===\n",
      "['name', 'wins', 'losses', 'height', 'weight', 'reach', 'stance', 'age', 'SLpM', 'sig_str_acc', 'SApM', 'str_def', 'td_avg', 'td_acc', 'td_def', 'sub_avg']\n",
      "Total Columns: 16\n",
      "\n",
      "=== Columns in Large Dataset ===\n",
      "['event_name', 'r_fighter', 'b_fighter', 'winner', 'weight_class', 'is_title_bout', 'gender', 'method', 'finish_round', 'total_rounds', 'time_sec', 'referee', 'r_kd', 'r_sig_str', 'r_sig_str_att', 'r_sig_str_acc', 'r_str', 'r_str_att', 'r_str_acc', 'r_td', 'r_td_att', 'r_td_acc', 'r_sub_att', 'r_rev', 'r_ctrl_sec', 'r_wins_total', 'r_losses_total', 'r_age', 'r_height', 'r_weight', 'r_reach', 'r_stance', 'r_SLpM_total', 'r_SApM_total', 'r_sig_str_acc_total', 'r_td_acc_total', 'r_str_def_total', 'r_td_def_total', 'r_sub_avg', 'r_td_avg', 'b_kd', 'b_sig_str', 'b_sig_str_att', 'b_sig_str_acc', 'b_str', 'b_str_att', 'b_str_acc', 'b_td', 'b_td_att', 'b_td_acc', 'b_sub_att', 'b_rev', 'b_ctrl_sec', 'b_wins_total', 'b_losses_total', 'b_age', 'b_height', 'b_weight', 'b_reach', 'b_stance', 'b_SLpM_total', 'b_SApM_total', 'b_sig_str_acc_total', 'b_td_acc_total', 'b_str_def_total', 'b_td_def_total', 'b_sub_avg', 'b_td_avg', 'kd_diff', 'sig_str_diff', 'sig_str_att_diff', 'sig_str_acc_diff', 'str_diff', 'str_att_diff', 'str_acc_diff', 'td_diff', 'td_att_diff', 'td_acc_diff', 'sub_att_diff', 'rev_diff', 'ctrl_sec_diff', 'wins_total_diff', 'losses_total_diff', 'age_diff', 'height_diff', 'weight_diff', 'reach_diff', 'SLpM_total_diff', 'SApM_total_diff', 'sig_str_acc_total_diff', 'td_acc_total_diff', 'str_def_total_diff', 'td_def_total_diff', 'sub_avg_diff', 'td_avg_diff']\n",
      "Total Columns: 95\n",
      "\n",
      "=== Columns in Medium Dataset ===\n",
      "['event', 'date', 'location', 'r_fighter', 'b_fighter', 'status', 'r_kd', 'b_kd', 'r_str', 'b_str', 'r_td', 'b_td', 'r_sub', 'b_sub', 'weight_class', 'method', 'method_detailed', 'round', 'time']\n",
      "Total Columns: 19\n",
      "\n",
      "=== Columns in UFC Dataset ===\n",
      "['Location', 'Fighter 1', 'Fighter 2', 'Fighter_1_KD', 'Fighter_2_KD', 'Fighter_1_STR', 'Fighter_2_STR', 'Fighter_1_TD', 'Fighter_2_TD', 'Fighter_1_SUB', 'Fighter_2_SUB', 'Weight_Class', 'Method', 'Round', 'Time', 'Event Name', 'Date', 'Winner']\n",
      "Total Columns: 18\n",
      "\n",
      "=== Columns in UFC Master Dataset ===\n",
      "['RedFighter', 'BlueFighter', 'RedOdds', 'BlueOdds', 'RedExpectedValue', 'BlueExpectedValue', 'Date', 'Location', 'Country', 'Winner', 'TitleBout', 'WeightClass', 'Gender', 'NumberOfRounds', 'BlueCurrentLoseStreak', 'BlueCurrentWinStreak', 'BlueDraws', 'BlueAvgSigStrLanded', 'BlueAvgSigStrPct', 'BlueAvgSubAtt', 'BlueAvgTDLanded', 'BlueAvgTDPct', 'BlueLongestWinStreak', 'BlueLosses', 'BlueTotalRoundsFought', 'BlueTotalTitleBouts', 'BlueWinsByDecisionMajority', 'BlueWinsByDecisionSplit', 'BlueWinsByDecisionUnanimous', 'BlueWinsByKO', 'BlueWinsBySubmission', 'BlueWinsByTKODoctorStoppage', 'BlueWins', 'BlueStance', 'BlueHeightCms', 'BlueReachCms', 'BlueWeightLbs', 'RedCurrentLoseStreak', 'RedCurrentWinStreak', 'RedDraws', 'RedAvgSigStrLanded', 'RedAvgSigStrPct', 'RedAvgSubAtt', 'RedAvgTDLanded', 'RedAvgTDPct', 'RedLongestWinStreak', 'RedLosses', 'RedTotalRoundsFought', 'RedTotalTitleBouts', 'RedWinsByDecisionMajority', 'RedWinsByDecisionSplit', 'RedWinsByDecisionUnanimous', 'RedWinsByKO', 'RedWinsBySubmission', 'RedWinsByTKODoctorStoppage', 'RedWins', 'RedStance', 'RedHeightCms', 'RedReachCms', 'RedWeightLbs', 'RedAge', 'BlueAge', 'LoseStreakDif', 'WinStreakDif', 'LongestWinStreakDif', 'WinDif', 'LossDif', 'TotalRoundDif', 'TotalTitleBoutDif', 'KODif', 'SubDif', 'HeightDif', 'ReachDif', 'AgeDif', 'SigStrDif', 'AvgSubAttDif', 'AvgTDDif', 'EmptyArena', 'BMatchWCRank', 'RMatchWCRank', 'RWFlyweightRank', 'RWFeatherweightRank', 'RWStrawweightRank', 'RWBantamweightRank', 'RHeavyweightRank', 'RLightHeavyweightRank', 'RMiddleweightRank', 'RWelterweightRank', 'RLightweightRank', 'RFeatherweightRank', 'RBantamweightRank', 'RFlyweightRank', 'RPFPRank', 'BWFlyweightRank', 'BWFeatherweightRank', 'BWStrawweightRank', 'BWBantamweightRank', 'BHeavyweightRank', 'BLightHeavyweightRank', 'BMiddleweightRank', 'BWelterweightRank', 'BLightweightRank', 'BFeatherweightRank', 'BBantamweightRank', 'BFlyweightRank', 'BPFPRank', 'BetterRank', 'Finish', 'FinishDetails', 'FinishRound', 'FinishRoundTime', 'TotalFightTimeSecs', 'RedDecOdds', 'BlueDecOdds', 'RSubOdds', 'BSubOdds', 'RKOOdds', 'BKOOdds']\n",
      "Total Columns: 118\n",
      "\n",
      "=== Columns in Completed Events Small Dataset ===\n",
      "['event', 'date', 'location']\n",
      "Total Columns: 3\n",
      "\n",
      "From the above datasets, we selected:\n",
      "- Large Dataset: for detailed fight information, including event names and fighters.\n",
      "- Medium Dataset: for additional event metadata, such as dates and locations.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### # Preprocess Selected Datasets\n",
    " **Description**:  \n",
    " Preprocess the selected datasets (`large_dataset` and `medium_dataset`):\n",
    " - Rename columns for consistency.\n",
    " - Standardize values in `event_name`.\n",
    " - Remove duplicates."
   ],
   "id": "d6c7160d240f428b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.156747Z",
     "start_time": "2024-12-22T19:25:38.107867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rename columns for consistency\n",
    "medium_dataset = medium_dataset.rename(columns={'event': 'event_name'})\n",
    "\n",
    "# Strip extra spaces and standardize to lowercase in 'event_name'\n",
    "large_dataset['event_name'] = large_dataset['event_name'].str.strip().str.lower()\n",
    "medium_dataset['event_name'] = medium_dataset['event_name'].str.strip().str.lower()\n",
    "\n",
    "# Check for duplicates based on 'event_name', 'r_fighter', and 'b_fighter'\n",
    "large_duplicates = large_dataset.duplicated(subset=['event_name', 'r_fighter', 'b_fighter'])\n",
    "medium_duplicates = medium_dataset.duplicated(subset=['event_name', 'date', 'location'])\n",
    "\n",
    "# Print the number of duplicates\n",
    "print(\"Duplicates in Large Dataset (based on 'event_name', 'r_fighter', 'b_fighter'):\", large_duplicates.sum())\n",
    "print(\"Duplicates in Medium Dataset (based on 'event_name', 'date', 'location'):\", medium_duplicates.sum())\n",
    "\n",
    "# Drop duplicates based on the relevant columns\n",
    "large_dataset = large_dataset.drop_duplicates(subset=['event_name', 'r_fighter', 'b_fighter'])\n",
    "medium_dataset = medium_dataset.drop_duplicates(subset=['event_name', 'date', 'location'])\n"
   ],
   "id": "8b8d756786cc9fb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in Large Dataset (based on 'event_name', 'r_fighter', 'b_fighter'): 0\n",
      "Duplicates in Medium Dataset (based on 'event_name', 'date', 'location'): 6898\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.197552Z",
     "start_time": "2024-12-22T19:25:38.191846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "duplicate_dates = medium_dataset[medium_dataset.duplicated(subset=['date'], keep=False)]\n",
    "print(duplicate_dates)\n"
   ],
   "id": "b1f16c46ef51b4d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    event_name        date  \\\n",
      "3596       ufc fight night: bader vs. nogueira  11/19/2016   \n",
      "3607       ufc fight night: mousasi vs. hall 2  11/19/2016   \n",
      "4581  ufc fight night: macdonald vs saffiedine   10/4/2014   \n",
      "4592          ufc fight night: nelson vs story   10/4/2014   \n",
      "4654   ufc fight night: henderson vs dos anjos   8/23/2014   \n",
      "4665            ufc fight night: bisping vs le   8/23/2014   \n",
      "4736      ufc fight night: swanson vs stephens   6/28/2014   \n",
      "4747     ufc fight night: te huna vs marquardt   6/28/2014   \n",
      "4779      ufc fight night: miocic vs maldonado   5/31/2014   \n",
      "4791         ufc fight night: munoz vs mousasi   5/31/2014   \n",
      "\n",
      "                                       location         r_fighter  \\\n",
      "3596               Sao Paulo, Sao Paulo, Brazil        Ryan Bader   \n",
      "3607  Belfast, Northern Ireland, United Kingdom    Gegard Mousasi   \n",
      "4581               Halifax, Nova Scotia, Canada    Rory MacDonald   \n",
      "4592                          Stockholm, Sweden        Rick Story   \n",
      "4654                       Tulsa, Oklahoma, USA  Rafael Dos Anjos   \n",
      "4665                               Macau, China   Michael Bisping   \n",
      "4736                    San Antonio, Texas, USA       Cub Swanson   \n",
      "4747                      Auckland, New Zealand    Nate Marquardt   \n",
      "4779                          Sao Paulo, Brazil      Stipe Miocic   \n",
      "4791                            Berlin, Germany    Gegard Mousasi   \n",
      "\n",
      "             b_fighter status  r_kd  b_kd  r_str  b_str  r_td  b_td  r_sub  \\\n",
      "3596  Rogerio Nogueira    win   0.0   0.0   86.0    3.0   5.0   0.0    1.0   \n",
      "3607        Uriah Hall    win   0.0   0.0   20.0   12.0   1.0   0.0    0.0   \n",
      "4581  Tarec Saffiedine    win   1.0   0.0   47.0   42.0   1.0   0.0    0.0   \n",
      "4592     Gunnar Nelson    win   1.0   0.0  168.0   53.0   1.0   1.0    0.0   \n",
      "4654  Benson Henderson    win   1.0   0.0   18.0   10.0   0.0   0.0    0.0   \n",
      "4665           Cung Le    win   1.0   0.0   92.0   38.0   0.0   0.0    0.0   \n",
      "4736   Jeremy Stephens    win   0.0   0.0   87.0   65.0   0.0   2.0    0.0   \n",
      "4747     James Te Huna    win   1.0   0.0   17.0    6.0   2.0   0.0    1.0   \n",
      "4779   Fabio Maldonado    win   1.0   0.0    8.0    2.0   0.0   0.0    0.0   \n",
      "4791        Mark Munoz    win   0.0   0.0   18.0    3.0   0.0   0.0    2.0   \n",
      "\n",
      "      b_sub       weight_class  method   method_detailed  round  time  \n",
      "3596    0.0  Light Heavyweight  KO/TKO           Punches    3.0  3:51  \n",
      "3607    0.0       Middleweight  KO/TKO           Punches    1.0  4:37  \n",
      "4581    0.0       Welterweight  KO/TKO             Punch    3.0  1:28  \n",
      "4592    0.0       Welterweight   S-DEC               NaN    5.0  5:00  \n",
      "4654    0.0        Lightweight  KO/TKO             Punch    1.0  2:31  \n",
      "4665    0.0       Middleweight  KO/TKO              Knee    4.0  0:57  \n",
      "4736    0.0      Featherweight   U-DEC               NaN    5.0  5:00  \n",
      "4747    0.0       Middleweight     SUB            Armbar    1.0  4:34  \n",
      "4779    0.0        Heavyweight  KO/TKO             Punch    1.0  0:35  \n",
      "4791    0.0       Middleweight     SUB  Rear Naked Choke    1.0  3:57  \n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### # Merge Datasets\n",
    "**Description**:  \n",
    "Merge `large_dataset` and `medium_dataset` on the `event_name` column."
   ],
   "id": "3be593f8dbb81b7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.236516Z",
     "start_time": "2024-12-22T19:25:38.230308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the datasets on 'event_name', excluding 'method_details'\n",
    "merged_dataset = pd.merge(\n",
    "    large_dataset, \n",
    "    medium_dataset[['event_name', 'date', 'location']], \n",
    "    on='event_name', \n",
    "    how='left'\n",
    ")"
   ],
   "id": "1b8900bc161f2e02",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.270449Z",
     "start_time": "2024-12-22T19:25:38.265875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the current column order\n",
    "columns_order = merged_dataset.columns.tolist()\n",
    "event_name_idx = columns_order.index('event_name')\n",
    "\n",
    "# Define the new column order\n",
    "new_columns_order = (\n",
    "    columns_order[:event_name_idx + 1] +  # Include 'event_name' and everything before it\n",
    "    ['date', 'location'] +               # Add 'date' and 'location' after 'event_name'\n",
    "    [col for col in columns_order if col not in ['date', 'location', 'event_name']]  # Remaining columns\n",
    ")\n",
    "\n",
    "# Apply the new column order using pd.Index for deduplication\n",
    "merged_dataset = merged_dataset.loc[:, pd.Index(new_columns_order).drop_duplicates()]\n"
   ],
   "id": "5acc00890f72771c",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### # Data Quality Checks\n",
    "**Description**:  \n",
    " Perform quality checks on the merged dataset:\n",
    " - Check for missing values.\n",
    " - Identify duplicate rows.\n",
    " - Display data types and unique values."
   ],
   "id": "dc8f42084c7e23db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.365620Z",
     "start_time": "2024-12-22T19:25:38.301402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to perform data quality checks\n",
    "def data_quality_checks(df, df_name):\n",
    "    print(f\"\\n=== Data Quality Checks for {df_name} ===\")\n",
    "\n",
    "    # Missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "    # Duplicate rows\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"\\nNumber of Duplicate Rows: {duplicate_rows}\")\n",
    "\n",
    "    # Data types\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # Unique values\n",
    "    print(\"\\nUnique Values Count:\")\n",
    "    print(df.nunique())\n",
    "\n",
    "    # Statistical summary for numerical columns\n",
    "    print(\"\\nStatistical Summary for Numerical Columns:\")\n",
    "    print(df.describe())\n",
    "\n",
    "\n",
    "# Perform quality checks on the merged dataset\n",
    "data_quality_checks(merged_dataset, \"Merged Dataset\")"
   ],
   "id": "3515e43e76ef2bc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Quality Checks for Merged Dataset ===\n",
      "\n",
      "Missing Values:\n",
      "date              12\n",
      "location          12\n",
      "total_rounds      31\n",
      "referee           32\n",
      "r_age             76\n",
      "r_reach          412\n",
      "r_stance          26\n",
      "b_age            190\n",
      "b_reach          888\n",
      "b_stance          68\n",
      "age_diff         213\n",
      "reach_diff      1038\n",
      "dtype: int64\n",
      "\n",
      "Number of Duplicate Rows: 0\n",
      "\n",
      "Data Types:\n",
      "event_name             object\n",
      "date                   object\n",
      "location               object\n",
      "r_fighter              object\n",
      "b_fighter              object\n",
      "                       ...   \n",
      "td_acc_total_diff     float64\n",
      "str_def_total_diff    float64\n",
      "td_def_total_diff     float64\n",
      "sub_avg_diff          float64\n",
      "td_avg_diff           float64\n",
      "Length: 97, dtype: object\n",
      "\n",
      "Unique Values Count:\n",
      "event_name             683\n",
      "date                   677\n",
      "location               168\n",
      "r_fighter             1796\n",
      "b_fighter             2301\n",
      "                      ... \n",
      "td_acc_total_diff      291\n",
      "str_def_total_diff     187\n",
      "td_def_total_diff      313\n",
      "sub_avg_diff           197\n",
      "td_avg_diff           1741\n",
      "Length: 97, dtype: int64\n",
      "\n",
      "Statistical Summary for Numerical Columns:\n",
      "       is_title_bout  finish_round  total_rounds     time_sec         r_kd  \\\n",
      "count    7439.000000   7439.000000   7408.000000  7439.000000  7439.000000   \n",
      "mean        0.055787      2.336336      3.128915   227.016669     0.249227   \n",
      "std         0.229525      1.015243      0.652739    98.169665     0.524210   \n",
      "min         0.000000      1.000000      1.000000     5.000000     0.000000   \n",
      "25%         0.000000      1.000000      3.000000   149.000000     0.000000   \n",
      "50%         0.000000      3.000000      3.000000   287.000000     0.000000   \n",
      "75%         0.000000      3.000000      3.000000   300.000000     0.000000   \n",
      "max         1.000000      5.000000      5.000000  1080.000000     5.000000   \n",
      "\n",
      "         r_sig_str  r_sig_str_att  r_sig_str_acc        r_str    r_str_att  \\\n",
      "count  7439.000000    7439.000000    7439.000000  7439.000000  7439.000000   \n",
      "mean     38.361204      83.786262       0.475335    58.199892   106.374916   \n",
      "std      32.871278      71.381806       0.165935    46.057503    79.812210   \n",
      "min       0.000000       0.000000       0.000000     0.000000     0.000000   \n",
      "25%      14.000000      29.000000       0.370000    22.000000    40.000000   \n",
      "50%      31.000000      66.000000       0.470000    50.000000    94.000000   \n",
      "75%      54.000000     120.000000       0.570000    83.000000   156.000000   \n",
      "max     445.000000     744.000000       1.000000   447.000000   746.000000   \n",
      "\n",
      "       ...  weight_diff   reach_diff  SLpM_total_diff  SApM_total_diff  \\\n",
      "count  ...  7439.000000  6401.000000      7439.000000      7439.000000   \n",
      "mean   ...     0.171000     0.190073         0.142594        -0.171643   \n",
      "std    ...     6.774199     8.252628         1.585610         1.691358   \n",
      "min    ...  -258.550000   -27.940000        -8.990000       -39.490000   \n",
      "25%    ...     0.000000    -5.080000        -0.860000        -1.040000   \n",
      "50%    ...     0.000000     0.000000         0.130000        -0.120000   \n",
      "75%    ...     0.000000     5.080000         1.160000         0.790000   \n",
      "max    ...    52.160000    33.020000        18.780000        12.640000   \n",
      "\n",
      "       sig_str_acc_total_diff  td_acc_total_diff  str_def_total_diff  \\\n",
      "count             7439.000000        7439.000000         7439.000000   \n",
      "mean                 0.012109           0.028164            0.020909   \n",
      "std                  0.119919           0.276307            0.113455   \n",
      "min                 -0.700000          -1.000000           -0.580000   \n",
      "25%                 -0.060000          -0.130000           -0.040000   \n",
      "50%                  0.010000           0.020000            0.010000   \n",
      "75%                  0.080000           0.190000            0.080000   \n",
      "max                  0.830000           1.000000            0.720000   \n",
      "\n",
      "       td_def_total_diff  sub_avg_diff  td_avg_diff  \n",
      "count        7439.000000   7439.000000  7439.000000  \n",
      "mean            0.037513      0.045651     0.134487  \n",
      "std             0.292107      1.052065     1.781598  \n",
      "min            -1.000000    -15.100000   -11.770000  \n",
      "25%            -0.140000     -0.400000    -0.870000  \n",
      "50%             0.020000      0.000000     0.090000  \n",
      "75%             0.210000      0.500000     1.160000  \n",
      "max             1.000000     13.800000    11.110000  \n",
      "\n",
      "[8 rows x 85 columns]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### # Block 6: Fill Missing Values\n",
    "**Description**:  \n",
    " Handle missing values in the merged dataset:\n",
    " - For string columns, fill with the most frequent value (mode).\n",
    " - For numeric columns, fill with the median.\n"
   ],
   "id": "7b26fcbd92e6fca0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.423991Z",
     "start_time": "2024-12-22T19:25:38.395816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill missing values for string and numeric columns\n",
    "def fill_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # For string columns\n",
    "            mode_value = df[col].mode()[0]  # Most frequent value\n",
    "            df[col] = df[col].fillna(mode_value)\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]):  # For numeric columns\n",
    "            df[col] = df[col].fillna(df[col].median())  # Median for numeric columns\n",
    "    return df\n",
    "\n",
    "# Apply the function to the merged dataset\n",
    "merged_dataset = fill_missing_values(merged_dataset)\n",
    "\n",
    "# Check for missing values after filling\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(merged_dataset.isnull().sum())"
   ],
   "id": "7fe3fb3684176411",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after filling:\n",
      "event_name            0\n",
      "date                  0\n",
      "location              0\n",
      "r_fighter             0\n",
      "b_fighter             0\n",
      "                     ..\n",
      "td_acc_total_diff     0\n",
      "str_def_total_diff    0\n",
      "td_def_total_diff     0\n",
      "sub_avg_diff          0\n",
      "td_avg_diff           0\n",
      "Length: 97, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T22:50:56.335725Z",
     "start_time": "2024-12-22T22:50:56.321409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to print dataset shape and column names\n",
    "def print_dataset_info(df, df_name):\n",
    "    print(f\"\\n=== Dataset: {df_name} ===\")\n",
    "    print(f\"Number of Rows: {df.shape[0]}\")\n",
    "    print(f\"Number of Columns: {df.shape[1]}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Print info for each dataset\n",
    "print_dataset_info(large_dataset, \"Large Dataset\")\n",
    "print_dataset_info(medium_dataset, \"Medium Dataset\")\n",
    "\n",
    "# If the merged dataset exists\n",
    "if 'merged_dataset' in locals():\n",
    "    print_dataset_info(merged_dataset, \"Merged Dataset\")\n"
   ],
   "id": "7634ced97716f4f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset: Large Dataset ===\n",
      "Number of Rows: 7439\n",
      "Number of Columns: 95\n",
      "Columns: ['event_name', 'r_fighter', 'b_fighter', 'winner', 'weight_class', 'is_title_bout', 'gender', 'method', 'finish_round', 'total_rounds', 'time_sec', 'referee', 'r_kd', 'r_sig_str', 'r_sig_str_att', 'r_sig_str_acc', 'r_str', 'r_str_att', 'r_str_acc', 'r_td', 'r_td_att', 'r_td_acc', 'r_sub_att', 'r_rev', 'r_ctrl_sec', 'r_wins_total', 'r_losses_total', 'r_age', 'r_height', 'r_weight', 'r_reach', 'r_stance', 'r_SLpM_total', 'r_SApM_total', 'r_sig_str_acc_total', 'r_td_acc_total', 'r_str_def_total', 'r_td_def_total', 'r_sub_avg', 'r_td_avg', 'b_kd', 'b_sig_str', 'b_sig_str_att', 'b_sig_str_acc', 'b_str', 'b_str_att', 'b_str_acc', 'b_td', 'b_td_att', 'b_td_acc', 'b_sub_att', 'b_rev', 'b_ctrl_sec', 'b_wins_total', 'b_losses_total', 'b_age', 'b_height', 'b_weight', 'b_reach', 'b_stance', 'b_SLpM_total', 'b_SApM_total', 'b_sig_str_acc_total', 'b_td_acc_total', 'b_str_def_total', 'b_td_def_total', 'b_sub_avg', 'b_td_avg', 'kd_diff', 'sig_str_diff', 'sig_str_att_diff', 'sig_str_acc_diff', 'str_diff', 'str_att_diff', 'str_acc_diff', 'td_diff', 'td_att_diff', 'td_acc_diff', 'sub_att_diff', 'rev_diff', 'ctrl_sec_diff', 'wins_total_diff', 'losses_total_diff', 'age_diff', 'height_diff', 'weight_diff', 'reach_diff', 'SLpM_total_diff', 'SApM_total_diff', 'sig_str_acc_total_diff', 'td_acc_total_diff', 'str_def_total_diff', 'td_def_total_diff', 'sub_avg_diff', 'td_avg_diff']\n",
      "\n",
      "=== Dataset: Medium Dataset ===\n",
      "Number of Rows: 684\n",
      "Number of Columns: 19\n",
      "Columns: ['event_name', 'date', 'location', 'r_fighter', 'b_fighter', 'status', 'r_kd', 'b_kd', 'r_str', 'b_str', 'r_td', 'b_td', 'r_sub', 'b_sub', 'weight_class', 'method', 'method_detailed', 'round', 'time']\n",
      "\n",
      "=== Dataset: Merged Dataset ===\n",
      "Number of Rows: 7439\n",
      "Number of Columns: 97\n",
      "Columns: ['event_name', 'date', 'location', 'r_fighter', 'b_fighter', 'winner', 'weight_class', 'is_title_bout', 'gender', 'method', 'finish_round', 'total_rounds', 'time_sec', 'referee', 'r_kd', 'r_sig_str', 'r_sig_str_att', 'r_sig_str_acc', 'r_str', 'r_str_att', 'r_str_acc', 'r_td', 'r_td_att', 'r_td_acc', 'r_sub_att', 'r_rev', 'r_ctrl_sec', 'r_wins_total', 'r_losses_total', 'r_age', 'r_height', 'r_weight', 'r_reach', 'r_stance', 'r_SLpM_total', 'r_SApM_total', 'r_sig_str_acc_total', 'r_td_acc_total', 'r_str_def_total', 'r_td_def_total', 'r_sub_avg', 'r_td_avg', 'b_kd', 'b_sig_str', 'b_sig_str_att', 'b_sig_str_acc', 'b_str', 'b_str_att', 'b_str_acc', 'b_td', 'b_td_att', 'b_td_acc', 'b_sub_att', 'b_rev', 'b_ctrl_sec', 'b_wins_total', 'b_losses_total', 'b_age', 'b_height', 'b_weight', 'b_reach', 'b_stance', 'b_SLpM_total', 'b_SApM_total', 'b_sig_str_acc_total', 'b_td_acc_total', 'b_str_def_total', 'b_td_def_total', 'b_sub_avg', 'b_td_avg', 'kd_diff', 'sig_str_diff', 'sig_str_att_diff', 'sig_str_acc_diff', 'str_diff', 'str_att_diff', 'str_acc_diff', 'td_diff', 'td_att_diff', 'td_acc_diff', 'sub_att_diff', 'rev_diff', 'ctrl_sec_diff', 'wins_total_diff', 'losses_total_diff', 'age_diff', 'height_diff', 'weight_diff', 'reach_diff', 'SLpM_total_diff', 'SApM_total_diff', 'sig_str_acc_total_diff', 'td_acc_total_diff', 'str_def_total_diff', 'td_def_total_diff', 'sub_avg_diff', 'td_avg_diff']\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Save the Final Dataset\n",
    " **Description**:  \n",
    " Save the cleaned and processed dataset to a file."
   ],
   "id": "5ca6950928821512"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:25:38.733417Z",
     "start_time": "2024-12-22T19:25:38.576407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the merged dataset to a file\n",
    "output_path = '../data/processed/ufc_data_final.csv'\n",
    "merged_dataset.to_csv(output_path, index=False)\n",
    "print(f\"\\nMerged dataset saved successfully at {output_path}\")"
   ],
   "id": "c340e8e0145b24aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged dataset saved successfully at ../data/processed/ufc_data_final.csv\n"
     ]
    }
   ],
   "execution_count": 73
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
